june 4, 1997 university of waterloo is seeking to form a long-term strategic relationship with a major vendor of switching, routing, and network-server products for the establishment and evolution of its "next-generation internet" campus network to interoperate with the onet "uni*net" and canarie "ca*net-ii" regional and national networks. the technologies to enable this next-generation campus network will centre around the integration of fast ethernet and gigabit ethernet switching with ip routing and ip multicast and ip bandwidth reservation and qos, and will extend to include servers for related network services such as address-assignment control, network-access device and user authentication, internet and intranet firewalls, secure web-based commerce, computer-telephony integration, and desktop/classroom videoconferencing and distance education. phase one of this project, to be in place for september 1997, requires the deployment of high-capacity backbone and workgroup switching/routing devices supporting ethernet, fast ethernet, interswitch vlans, and ip multicast. the initial core of the network will be a fast ethernet backbone of from eight to twelve fibre-connected switching/routing/multicast modular devices, each of which provides from 12 to 48 fast ethernet fibre and/or copper links to fully-compatible workgroup switching devices. a range of workgroup devices is required: some workgroups will require from 24 to 48 10mbps ports each capable of supporting multiple devices and two or more 100mbps ports for the fibre uplink and for local utp-connected workgroup-server devices; others will require from 12 to 24 auto-sensing 10/100mbps ports and a 100mbps fibre- uplink port. one of the core devices must also support multiple atm links (initially, two or more oc-3 ports and one or two t1 circuit-emulation cards). the number of workgroup switches is expected to range from about thirty to perhaps sixty over the duration of phase one. phase two of the project will extend the capacity of the network and will continue to extend the number of workgroup switches. the vendor will enter into some form of on-going "return for credit" agreement to upgrade/replace the phase-one devices to support ieee-standardized gigabit ethernet and interswitch vlans once those standards are finalized, to extend the use of atm to whatever extent uw perceives necessary, and to incorporate new function and devices or modules as the vendor evolves its products so that the uw campus network can continue to evolve in pace with the next-generation internet community. overview and background documents that were created to facilitate uw-internal discussion are available in the "next-generation network" section of the uw campus networks webspace (http://www.ist.uwaterloo.ca/cn/). address questions to roger watt <rwwatt@uwaterloo.ca>. july 15, 1997 (clarifications) topology considerations the new backbone of the uw campus network will be a core of nine nodes. we want sufficient multiple paths such that an outage of any one of the nine will not prevent communication among the other eight. routing considerations the uw campus network is primarily an ip network, but it also carries some amount of appletalk and must continue to do so for the immediate future. the mc core node must be a full-function switching/routing node with multiple ethernet and multiple atm links, including uw's external connection (an 155mbps atm link to onet networking's k-w switching/routing node, located in the same equipment room as uw's mc node). we currently use an ip "default route" for the external link, but we may soon need to move to some external routing protocol such as bgp4. the mc-node device must include the ability to configure special atm-layer external circuits, and the ability to impose accept/deny "filtering" conditions on all ip traffic to/from the external connection by a variety of controls including ip addresses and ip/tcp/udp protocol types. we currently capture and report on counts of ip packets and bytes to/from the external connection, and wish to continue to do so. the ideal is that layer-three traffic between any two links on one of the nine core nodes does not have to leave that node. it may not be essential that all other eight nodes have full routing functionality, but to avoid single-point-of-failure, at least one other node must. the pattern of traffic within the uw network dictates that that be the e2 node. for the other seven nodes, it may be sufficient that they obtain and use routing information from the two full-function nodes. it will be a significant asset if this same ability to learn and use routing information can be extended out to the workgroup switches. on the matter of atm in its production environment, uw intends to pursue voice and video as ip-based applications, when and as the ability to do so matures within the internet community. while there is an interest in atm-layer connectivity in several research groups, uw has no immediate production need to use atm as the vehicle to interconnect these nine nodes, and it is not clear whether the need to extend atm to the other eight nodes will arise within the remainder of this decade. however, special needs may arise from time to time, and uw is not unwilling to consider an atm core today if the price is sufficiently compelling to outweigh the added staff-impact costs of complexity. implementation timing and migration we need to have some of this in place by september 1997, but it will be impossible to do the full implementation by then. we are unable to commit to any given schedule other than one we will make up as we go, driven only by our initial implementation successes and our need to deploy new equipment and schedule cutovers so as to avoid substantive disruption to the current production network. questions, concerns, etc please clarify the manner in which ip routing works between the devices you are proposing. examples. what ip route-advertisement protocols does the device accept/advertise? how does a node that does not have full routing functionality acquire information about routes and the loss of routes? please clarify the manner in which ip multicast works between the devices you are proposing. examples. how do the core nodes communicate group-membership information out to the workgroup nodes? please comment on your ability to adapt to our schedule and your ability to loan us equipment to assist in the transition from the old network to the new network. examples. can you adjust to our need for on-going assistance in planning a migration strategy? can you loan us an fddi interface for the mc core node so that we can interconnect the current backbone to the new backbone?